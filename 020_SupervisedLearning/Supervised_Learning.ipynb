{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning with Phishing Email Data\n",
    "\n",
    "This notebook explores core concepts and and provides examples of machine learning.  We will use phishing emails as a dataset and compare statistcal learning methods, such as Logistic Regression, Support Vector Machines, Decision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import os \n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report,ConfusionMatrixDisplay,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect GPU device\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset that will be used to train and test the different models was from https://www.kaggle.com/datasets/subhajournal/phishingemails.  It was pre-labeled as \"Safe Email\" or \"Phishing Email\".  The data will be cleaned and prepared for training machine learning models with Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data into a Pandas dataframe\n",
    "#df = pd.read_csv('../datasets/Phishing_Email.csv')\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RiverGumSecurity/Datasets/refs/heads/main/Kaggle/Phishing_Email.csv.gz')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information on the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null values in the data - these can cause issues for computation later in the notebook\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values in place, drop Unamed:0 column, drop duplicates\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df.dropna(inplace=True,axis=0)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the count of Email types, a Safe Email or a Phishing Email\n",
    "df['Email Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts of Safe Email vs Phishing Email\n",
    "df['Email Type'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to further process and clean the data. This is a binary classification problem, and we need to assign a label (a 1 or a 0) to the email categories. Then we will remove URLS and non word characters from the emails - we are interested in the similarities of the text itself.  Then we lowercase all of the characters, convert all multiple whitespace characters to single whitespace, and remove any trailing whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Email Type\n",
    "lbl = LabelEncoder()\n",
    "df['Email Type'] = lbl.fit_transform(df['Email Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text.\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "df['Email Text']=df['Email Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the text into a TF-IDF (Term Frequencey Inverse Document Frequency) matrix. This a statistical measure that evaluates how relevant a word is to a document in a collection of documents. It combines two metrics: the number of times a word appears in a document (term frequency) and the inverse document frequency of the word across the entire set of documents where each email is a document.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "The Email Type columns is then converted into a numpy array.  Data from both calculations is stored in a class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert email text to an array of vectors, removing stop words\n",
    "tf = TfidfVectorizer(stop_words='english',max_features=10000) #dimension reduction\n",
    "feature_x = tf.fit_transform(df['Email Text']).toarray()\n",
    "\n",
    "# convert the label into numpy array\n",
    "y_tf = np.array(df['Email Type']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science and traning and testing machine learning models, it is common practice to split the data into traning and validation splits.  Usually this is an 80/20 split where 80% of the data is used for training the model, and 20% is used for validation. The validation process is used to measure the accuracy of the model using various statistical measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and testing data groups, 80 percent training, 20 percent testing\n",
    "X_tr,X_tst,y_tr,y_tst = train_test_split(feature_x,y_tf,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now that we have split our data into traning and validation sets, we are ready for our first machine learning model that will be able to tell if an email is phishing or not based on the text of the email.  The first model we will explore is Logistic Regression.\n",
    "\n",
    "Logistic regression is a statistical method used for binary classification, where the goal is to predict the probability that a given input belongs to one of two categories. It models the relationship between a dependent binary variable and one or more independent variables using the logistic function, producing an output between 0 and 1. This output can then be thresholded to classify the input into one of the two categories.\n",
    "\n",
    "A good explanation of how this works can be found from the good folks at StatQuest:\n",
    "\n",
    "https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_tr,y_tr)\n",
    "\n",
    "pred_lg = lg.predict(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "\n",
    "- upper left - number of emails predicted to be phishing and are actually phishing (True Positive)\n",
    "\n",
    "- upper right - number of emails predicted as not phishing that are actually phishing (False Positive)\n",
    "\n",
    "- lower left - number emails predicted to be phishing that are actually not phishing (False Negative)\n",
    "\n",
    "- lower right - number of emails predicted ast not phishing that are actually not phishing (True Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate the accuracy and the f1 score of the Logistic Regression model.\n",
    "\n",
    "lr_accu = accuracy_score(y_tst,pred_lg)*100\n",
    "lr_f1 = f1_score(y_tst,pred_lg)*100\n",
    "\n",
    "print(\"The Logistic Regression model accuracy score was \" + str(lr_accu) + \"\\n\")\n",
    "print(\"The Logistic Regression model F1 score was \" + str(lr_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_lg))\n",
    "\n",
    "clf_lg = confusion_matrix(y_tst,pred_lg)\n",
    "cx_ = ConfusionMatrixDisplay(clf_lg,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "https://scikit-learn.org/stable/modules/svm.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(X_tr,y_tr)\n",
    "\n",
    "pred_svm = svm.predict(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accu = accuracy_score(y_tst,pred_svm)*100\n",
    "svm_f1 = f1_score(y_tst,pred_svm)*100\n",
    "\n",
    "\n",
    "print(\"The SVM model accuracy score was \" + str(svm_accu) + \"\\n\")\n",
    "print(\"The SVM model F1 score was \" + str(svm_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_svm))\n",
    "\n",
    "clf_lg = confusion_matrix(y_tst,pred_svm)\n",
    "cx_ = ConfusionMatrixDisplay(clf_lg,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=The%20multinomial%20Naive%20Bayes%20classifier,tf%2Didf%20may%20also%20work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_nb = nb.predict(X_tst)\n",
    "nb_accu = accuracy_score(y_tst,pred_nb)*100\n",
    "nb_f1 = f1_score(y_tst,pred_nb)*100\n",
    "\n",
    "print(\"The Naive Bayes model accuracy score was \" + str(nb_accu) + \"\\n\")\n",
    "print(\"The Maive Bayes model F1 score was \" + str(nb_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_nb))\n",
    "\n",
    "clf_nb = confusion_matrix(y_tst,pred_nb)\n",
    "cx_ = ConfusionMatrixDisplay(clf_nb,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "upper left - number of emails predicted to be phishing and are actually phishing (True Positive)\n",
    "upper right - number of emails predicted as not phishing that are actually phishing (False Positive)\n",
    "lower left - number emails predicted to be phishing that are actually not phishing (False Negative)\n",
    "lower right - number of emails predicted ast not phishing that are actually not phishing (True Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt = dt.predict(X_tst)\n",
    "dt_accu = accuracy_score(y_tst,pred_dt)*100\n",
    "dt_f1 = f1_score(y_tst,pred_dt)*100\n",
    "\n",
    "print(\"The Decision Tree model accuracy score was \" + str(dt_accu) + \"\\n\")\n",
    "print(\"The Decision Tree model F1 score was \" + str(dt_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_dt))\n",
    "\n",
    "clf_dt = confusion_matrix(y_tst,pred_dt)\n",
    "cx_ = ConfusionMatrixDisplay(clf_dt,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(X_tst)\n",
    "rf_accu = accuracy_score(y_tst,pred_rf)*100\n",
    "rf_f1 = f1_score(y_tst,pred_rf)*100\n",
    "\n",
    "print(\"The Random Forest model accuracy score was \" + str(rf_accu) + \"\\n\")\n",
    "print(\"The Random Forest model F1 score was \" + str(rf_f1) + \"\\n\")\n",
    "\n",
    "print(classification_report(y_tst,pred_rf))\n",
    "\n",
    "clf_rf = confusion_matrix(y_tst,pred_rf)\n",
    "cx_ = ConfusionMatrixDisplay(clf_rf,display_labels=['phishing_mail','safe_mail']).plot()\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do - set up table of models and comparisons\n",
    "\n",
    "accu_values = [lr_accu,svm_accu,nb_accu,dt_accu,rf_accu]\n",
    "row_labels = [\"Logistic Regression\", \"SVM\", \"Naive Bayes\",\"Decision Tree\",\"Random Forest\"]\n",
    "comp_df = pd.DataFrame(accu_values, columns=[\"accuracy\"], index=row_labels)\n",
    "print(comp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
