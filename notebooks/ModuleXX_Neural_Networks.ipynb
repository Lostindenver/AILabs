{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b028a26-f0e1-4c50-bad5-0544adf04233",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/RiverGumSecurity/AILabs/blob/dev-derek/labs/Module02_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7318404-f202-4515-bc11-86022e59e744",
   "metadata": {},
   "source": [
    "# Supervised Learning and Neural Networks with Phishing Email Data\n",
    "\n",
    "Neural networks are a subset of machine learning algorithms inspired by the human brain's structure and function. They consist of layers of interconnected \"neurons\" that transform the input data through weighted connections to produce an output. Neural networks are particularly powerful for complex tasks like image recognition and natural language processing.\n",
    "\n",
    "Neural networks consist of an input layer, one or more hidden layers, and an output layer. These layers consist of \"neurons\" where each neuron processes input data by applying a weight and an activation function (like sigmoid or ReLU) to produce an output. The training (or learning) process adjusts the weights of the connections between neurons using algorithms like backpropagation and optimization techniques like gradient descent. Neural networks, particularly deep neural networks (deep learning), can model highly complex relationships between inputs and outputs by learning hierarchical feature representations in the hidden layers. Deep learning neural networks typically contain three or more hidden layers.\n",
    "\n",
    "<center><img src=\"https://images.edrawsoft.com/articles/neural-network-diagram/example1.png\" width=\"800\" height=\"600\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037f4ce-8b9a-444b-bdaa-0f36208eacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import os \n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report,ConfusionMatrixDisplay,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding,GRU,LSTM,Bidirectional,SimpleRNN\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6e503-b7a9-472a-b6f1-e00cd2284f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supress debug warnings in training output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses INFO and WARNING messages\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982cbe9-eb9a-4f86-ae8b-ceccd31fedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed static value for consistent results\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e37ef-b7d4-42df-958a-440d1640f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect GPU device\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e67c6-f1e1-4071-90fd-1bc66c425787",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses INFO and WARNING messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d6a82-d65f-4413-bff4-3f53aa366eba",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset that will be used to train and test the different models was from https://www.kaggle.com/datasets/subhajournal/phishingemails.  It was pre-labeled as \"Safe Email\" or \"Phishing Email\".  The data will be cleaned and prepared for training machine learning models with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc29abc-c9e0-4cbf-9c36-5d8e5506a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data into a Pandas dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RiverGumSecurity/Datasets/main/Kaggle/Phishing_Email.csv.gz')\n",
    "#df = pd.read_csv('../datasets/Phishing_Email.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46408f-7be9-4b0e-9074-dc05def90709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information on the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9cd602-2141-4cac-8de7-0ed41cde6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values in place, drop Unamed:0 column, drop duplicates\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df.dropna(inplace=True,axis=0)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0e2d2-738b-4471-9514-f226de5d3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c8644-ab23-4e99-a6f6-17df7ddd2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b5b12-ab7a-4a85-ad4b-07b4b68af6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the count of Email types, a Safe Email or a Phishing Email\n",
    "df['Email Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93bda6a-4af6-492a-93b8-aff225609d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts of Safe Email vs Phishing Email\n",
    "df['Email Type'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d52a3-db0e-4649-8700-e04fe6971217",
   "metadata": {},
   "source": [
    "Now we need to further process and clean the data. This is a binary classification problem, and we need to assign a label (a 1 or a 0) to the email categories. Then we will remove URLS and non word characters from the emails - we are interested in the similarities of the text itself.  Then we lowercase all of the characters, convert all multiple whitespace characters to single whitespace, and remove any trailing whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e191c8-4f2a-4878-a652-a0f0a82472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Email Type\n",
    "lbl = LabelEncoder()\n",
    "df['Email Type'] = lbl.fit_transform(df['Email Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e153e-a279-4ee5-8e66-1153784a78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text.\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "df['Email Text']=df['Email Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5fb38-80a5-456b-8f4e-068e10c0bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc76d3-7e26-40ba-aa9a-715af4bf2788",
   "metadata": {},
   "source": [
    "## Simple Neural Network\n",
    "\n",
    "The [`SimpleRNN`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN) layer in TensorFlow is a [recurrent neural network (RNN)]9https://en.wikipedia.org/wiki/Recurrent_neural_network) layer that processes sequential data, making it suitable for tasks like time series prediction or text generation. Each unit in SimpleRNN maintains a hidden state across time steps, allowing the model to \"remember\" previous inputs in the sequence. It supports configurations for returning only the final output or the entire sequence, and can also be stacked with other layers for deeper architectures. This layer is simpler and faster than more complex RNN types, like LSTM or GRU, but may struggle with longer sequences.\n",
    "\n",
    "Because our email messages are variable length, we need to fix the length of each vector we create. In deep learning, itâ€™s often beneficial to have inputs of consistent shapes. Setting max_len ensures that all sequences are padded or truncated to a specific length, allowing you to batch-process sequences more efficiently. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a669b-db0d-427a-aafb-782ee1a4e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set max_len\n",
    "max_len = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5beb8-cd63-446a-8ca1-ed2802361dae",
   "metadata": {},
   "source": [
    "We initalize a new [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) class which is used for preprocessing text data by converting words or characters into numerical representations that a machine learning model can understand. In general, a token is a word or a character.  In our case, a token is a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d6831-73dc-4062-a912-2d9d7a3878a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize new instance of Tokenizer class.\n",
    "tk = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35190462-b1e6-4d0f-b5a2-2ce9c22d6133",
   "metadata": {},
   "source": [
    "The next step is to use `fit_on_texts` method in the 'Tokenizer' class to  processes each text entry in the `Email Text` column of the Pandas data frame to build a vocabulary, where each unique word (or token) is assigned a unique integer index based on its frequency across the entire dataset. It then creates a word index mapping each word (token) to a unique integer in each email. \n",
    "\n",
    "Then we use the `texts_to_sequences` method to create a list of integer sequence for each email from our word index mappings.  These sequence of integers are then converted to vectors of fixed length (256 from our max_len variable) and padded or truncated as necessary and stored in a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34b585-b929-4e2b-8b58-637d0f30dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text\n",
    "tk.fit_on_texts(df['Email Text'])\n",
    "sequences = tk.texts_to_sequences(df['Email Text'])\n",
    "vector = pad_sequences(sequences,padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e493b-0519-4a42-abff-f91f30093e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of rows in the vector numpy array, matches the number of emails in our dataset.\n",
    "vector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2b0cd-64ca-457d-a108-d039a3c5176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of our word index\n",
    "len(tk.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95781310-2989-452f-9f9f-62cab6f11ac4",
   "metadata": {},
   "source": [
    "Now we set the `max_features` parameter to limit our overall vocabulary size to the most frequent words. There are two main reasons for this:\n",
    "\n",
    "- Reduces Memory Usage: In many NLP tasks, datasets contain thousands or millions of unique words. Limiting the vocabulary size to the most frequent words helps reduce memory and computational requirements, which is especially helpful when working with limited resources or large datasets.\n",
    "- Improves Model Generalization: High vocabulary sizes can lead to overfitting, as the model might memorize rare words that do not generalize well to new data. Setting max_features forces the model to focus on the most important and commonly occurring words, which generally improves performance on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b74f65-b35c-4ca9-90ef-5a3fdd801193",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c5a6e-3f69-4236-9e93-2516832b1fc0",
   "metadata": {},
   "source": [
    "Now we split our dataset into training and testing sets using the `train_test_split function` from scikit-learn.  We will train our neural network on 80 percent of the data, then evaluate the accuracy on the remaining 20 percent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2ee7a-bdfa-4a93-b6d3-98821a2f4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vector,df['Email Type'], test_size=0.2, random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca54a4d-2349-4ce0-ba6d-04c87231a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_srnn = Sequential() # Sequential() API\n",
    "model_srnn.add(Embedding(len(tk.word_index)+1,50))\n",
    "model_srnn.add(SimpleRNN(units=100))\n",
    "model_srnn.add(Dropout(0.5))\n",
    "model_srnn .add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21b47b-3223-43e4-bac2-0550a10d8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_srnn.compile(loss='binary_crossentropy' , optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91d768-8d25-43d1-bd7a-1aad1fcdf5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_srnn  = model_srnn.fit(x_train,y_train, epochs=20, batch_size=16, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0debcd-5aae-4804-a8f5-44ccbeb0e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(historical_srnn.history)\n",
    "\n",
    "pd.DataFrame(historical_srnn.history)[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "pd.DataFrame(historical_srnn.history)[['loss', 'val_loss']].plot()\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae132bf-45e3-4454-8cb6-c572297763ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_smp = model_srnn.predict(x_test)\n",
    "y_pred_smp = (y_pred_prob_smp > 0.5).astype(int)\n",
    "\n",
    "\n",
    "cnf_smp = confusion_matrix(y_test,y_pred_smp)\n",
    "ax_smp = ConfusionMatrixDisplay(confusion_matrix=cnf_smp,display_labels=['phishing','normal']).plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f7d61-ec2d-4da3-b3c8-78c328970e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "srnn_loss, srnn_accu = model_srnn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "srnn_accu = (srnn_accu*100)\n",
    "\n",
    "# Display the accuracy value\n",
    "print(f'The accuracy of the SRNN model on the test data set was: {srnn_accu:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05ec1a-26d0-4ed2-b08a-b3485e7b0f84",
   "metadata": {},
   "source": [
    "## LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61136d61-5da7-42a7-ae0a-3f2fd924b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential() # Sequential() API\n",
    "model_lstm.add(Embedding(len(tk.word_index)+1,50))\n",
    "model_lstm.add(LSTM(units=100))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc623ba-ed84-4f7e-9c4a-d0eec5e2f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(loss='binary_crossentropy' , optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca57d1a-2bc9-40f8-885f-3d274da3ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_lstm  = model_lstm.fit(x_train,y_train, epochs=20, batch_size=16, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c247a-aea8-4b6c-8922-08f1095311af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_results = model_lstm.evaluate(x_test, y_test)\n",
    "lstm_loss = lstm_results[0]  # Extract the loss from the results\n",
    "lstm_accu = (lstm_results[1]*100)  # Extract the accuracy from the results\n",
    "\n",
    "print(f\"Model Loss: {lstm_loss}\")\n",
    "print(f\"Model Accuracy: {lstm_accu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198118d1-a346-4099-9429-a1c1c31fbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model_lstm.predict(x_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc49587-9271-4168-aad0-c0d642073953",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(historical_lstm.history)\n",
    "\n",
    "pd.DataFrame(historical_lstm.history)[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "pd.DataFrame(historical_lstm.history)[['loss', 'val_loss']].plot()\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fbd20-588f-4165-b84f-f2943bd751a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = confusion_matrix(y_test,y_pred)\n",
    "ax = ConfusionMatrixDisplay(confusion_matrix=cnf,display_labels=['pishing','normal'])\n",
    "ax.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeeef5d-62db-4b7f-8a92-9171dd0a0cb1",
   "metadata": {},
   "source": [
    "## Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659e4e9-c477-4e90-90a4-a82ff56b6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi = Sequential() # Sequential() API\n",
    "model_bi.add(Embedding(len(tk.word_index)+1,50))\n",
    "model_bi.add(Bidirectional(LSTM(units=100)))\n",
    "model_bi.add(Dropout(0.5))\n",
    "model_bi.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d79d71-a3c3-453a-996a-fa72376167cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi.compile(loss='binary_crossentropy' , optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80bd43c-999d-4c95-9242-3cf1b569652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_bi  = model_bi.fit(x_train,y_train, epochs=20, batch_size=16, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b7bc6-55f5-42d0-bb18-64fcb655b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_results = model_bi.evaluate(x_test, y_test)\n",
    "bi_loss = bi_results[0]  # Extract the loss from the results\n",
    "bi_accu = (bi_results[1]*100)  # Extract the accuracy from the results\n",
    "\n",
    "print(f\"Model Loss: {bi_loss}\")\n",
    "print(f\"Model Accuracy: {bi_accu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf4fcd-b7b4-4fe1-9510-bc8cc9932d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_bi = model_bi.predict(x_test)\n",
    "y_pred_bi = (y_pred_prob_bi > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41494fc-050a-45de-b636-bc6b72a33dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(historical_bi.history)\n",
    "\n",
    "pd.DataFrame(historical_bi.history)[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "pd.DataFrame(historical_bi.history)[['loss', 'val_loss']].plot()\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab2c60-5199-4677-93c1-32c2586b177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_bi = confusion_matrix(y_test,y_pred_bi)\n",
    "ax_bi = ConfusionMatrixDisplay(confusion_matrix=cnf_bi,display_labels=['Phishing','Normal'])\n",
    "ax_bi.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8594c-d2c1-4bc4-b253-72ee7f3183c0",
   "metadata": {},
   "source": [
    "### Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5d542-f833-4dcc-8625-75404cfe698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = Sequential() # Sequential() API\n",
    "model_gru.add(Embedding(len(tk.word_index)+1,50))\n",
    "model_gru.add(GRU(units=100))\n",
    "model_gru.add(Dropout(0.5))\n",
    "model_gru.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f838ca-00c3-453a-a5c0-3381ed6b1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.compile(loss='binary_crossentropy' , optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06f468-1a48-4b26-9a12-400c9ec55aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_gru = model_gru.fit(x_train,y_train, epochs=20, batch_size=16, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f03fb-7a85-4170-be70-7e9791c8b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_results = model_gru.evaluate(x_test, y_test)\n",
    "gru_loss = gru_results[0]  # Extract the loss from the results\n",
    "gru_accu = (gru_results[1]*100)  # Extract the accuracy from the results\n",
    "\n",
    "print(f\"Model Loss: {gru_loss}\")\n",
    "print(f\"Model Accuracy: {gru_accu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f18b0-8afb-45ce-a7c7-e79a2a219613",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_gru = model_gru.predict(x_test)\n",
    "y_pred_gru = (y_pred_prob_gru > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8e8e9-2ac2-4c79-b51b-527edb3e782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(historical_gru.history)\n",
    "\n",
    "pd.DataFrame(historical_gru.history)[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "pd.DataFrame(historical_gru.history)[['loss', 'val_loss']].plot()\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7eed0-d897-4742-abd0-14d14a63c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_gru = confusion_matrix(y_test,y_pred_gru)\n",
    "ax_gru = ConfusionMatrixDisplay(confusion_matrix=cnf_gru,display_labels=['Pishing','normal'])\n",
    "ax_gru.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba33340-39f0-490b-8377-deb587641cad",
   "metadata": {},
   "source": [
    "# Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710203ee-a60d-4aa1-9eea-1e12b20f37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do - set up table of models and comparisons\n",
    "\n",
    "accu_values = [srnn_accu,lstm_accu, bi_accu, gru_accu]\n",
    "row_labels = [\"Simple RNN\", \"LSTM Neural Network\", \"Bidirectional Neural Network\", \"Gated Recurrent Unit\"]\n",
    "comp_df = pd.DataFrame(accu_values, columns=[\"accuracy\"], index=row_labels)\n",
    "print(comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2782c-1e56-4a42-bb1f-da04a137215d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
